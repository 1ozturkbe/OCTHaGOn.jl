{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data from aerospace database.\n",
    "using CSV, DataFrames, Statistics, Random\n",
    "include(\"augment.jl\")\n",
    "include(\"bin_to_leaves.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional extra cores\n",
    "using Distributed\n",
    "addprocs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Re\", \"thick\", \"M\", \"C_L\"];\n",
    "X = CSV.read(\"airfoil_X.csv\", copycols=true, header=columns, delim=\",\");\n",
    "Y = CSV.read(\"airfoil_Y.csv\", copycols=true, header=[\"C_D\"], delim=\",\");\n",
    "X = Matrix(X); Y = Matrix(Y);\n",
    "Re = Array(range(10000, stop=35000, step=5000));\n",
    "thick = [100,110,120,130,140,145];\n",
    "M = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9];\n",
    "cl = Array(range(0.35, stop=0.70, step=0.05));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting some perspectives on the data\n",
    "using Plots\n",
    "plt = Plots.plot(X[:,3], X[:,4], Y[:,1], seriestype=:scatter, markersize = 2)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "(train_X, train_y), (test_X, test_y) = IAI.split_data(:regression, seed=1, Matrix(X), Matrix(Y), train_proportion=0.8);\n",
    "size(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do fun things with the data (everything has already been taken a log of!) \n",
    "lnr = IAI.OptimalTreeRegressor(random_seed=1, max_depth=7, cp=1e-8,  minbucket=0.02, regression_sparsity=:all, \n",
    "    regression_lambda = 0.0001)\n",
    "IAI.fit!(lnr, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation of best tree\n",
    "grids = IAI.GridSearch(lnr, max_depth = [2,3], minbucket=[0.03,0.06,0.09,0.12,0.15])\n",
    "IAI.fit!(grids, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing best learner\n",
    "lnr = IAI.get_learner(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about trying sparse hyperplane splits? \n",
    "lnr = IAI.OptimalTreeRegressor(random_seed=1, max_depth=3, cp=0.001, minbucket=0.05, \n",
    "    hyperplane_config=(sparsity=2,), regression_sparsity=:all, regression_lambda = 0.0001, fast_num_support_restarts =10)\n",
    "grids = IAI.GridSearch(lnr, max_depth = [2,3], minbucket=[0.03,0.06,0.09,0.12,0.15])\n",
    "IAI.fit!(grids, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing best learner\n",
    "lnr = IAI.get_learner(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE errors \n",
    "println(\"Training MSE:\", 1 - IAI.score(lnr, train_X, train_y, criterion=:mse))\n",
    "println(\"Test MSE:\", 1- IAI.score(lnr, test_X, test_y, criterion=:mse))\n",
    "# MSE error of global posynomial\n",
    "Re = exp.(test_X[:,1]); thickness = exp.(test_X[:,2]); M = exp.(test_X[:,3]); C_L = exp.(test_X[:,4]); C_D = exp.(test_y);\n",
    "CDp = 0.0470226 .* (Re).^-0.388166 .* thickness.^0.782129 .* (M).^-0.339824 .* (C_L).^0.94829 +\n",
    "    190.63 .* (Re).^-0.218175 .* thickness.^3.94137 .* (M).^19.2346 .* (C_L).^1.14997 +\n",
    "    1.62158 .* (Re).^-0.549562 .* thickness.^1.2895 .* (M).^3.03057 .* (C_L).^1.77464 +\n",
    "    2.91642e-12 .* (Re).^1.18062 .* thickness.^-1.75547 .* (M).^0.105431 .*(C_L).^-1.4407;\n",
    "CDp = CDp.^(1/1.64722);\n",
    "MSEposy = sum((log.(C_D)-log.(CDp)).^2)/size(C_D,1)\n",
    "println(\"Test MSE of global posynomial: \", MSEposy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting some perspectives on the data, with predictions\n",
    "using Plots\n",
    "leaf_index, all_leaves = bin_to_leaves(lnr, X);\n",
    "predictions = IAI.predict(lnr, X)\n",
    "# plt = Plots.plot(X[:,1], X[:,4], Y[:,1], seriestype=:scatter, markersize = 2)\n",
    "plt = Plots.plot(X[:,3], X[:,4], predictions, zcolor=leaf_index, seriestype=:scatter, markersize = 2)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's try convex regression... this is the MIO approach for HW2\n",
    "include(\"convexRegress.jl\");\n",
    "thetas, ksis = convexRegress(Y,X,10,1/1000, 1e-4)\n",
    "println(\"Test MSE of convex regression: \", mean((thetas-Y).^2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting results\n",
    "plt = Plots.plot(X[:,3], X[:,4], Y[:,1], seriestype=:scatter, markersize = 2)\n",
    "plt = Plots.plot!(X[:,3], X[:,4], thetas, seriestype=:scatter, markersize = 2)\n",
    "display(plt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
